{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd5c7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import pyphen\n",
    "import nltk\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "console_out = logging.StreamHandler(sys.stdout)\n",
    "console_out.setLevel(logging.DEBUG)\n",
    "logger.addHandler(console_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdac710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    \"\"\"\n",
    "    commandline arguments parser\n",
    "    return text to be cleaned\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"수정할 텍스트를 입력합니다\"\n",
    "    )\n",
    "    \n",
    "    parser.add_argument('text', metavar='input text', type=str)\n",
    "    args = parser.parse_args()\n",
    "    return args.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40f8ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_input(text):\n",
    "    \"\"\"\n",
    "    text cleaning function\n",
    "    parameter text: user input text\n",
    "    delete characters not ascii, and return text\n",
    "    \"\"\"\n",
    "    return str(text.encode().decode('ascii', errors='ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d2936dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(text):\n",
    "    \"\"\"\n",
    "    tokenize cleaned text\n",
    "    parameter text: cleaned text\n",
    "    return tokenized text\n",
    "    \"\"\"\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    tokens = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96efcc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_word_length(tokens):\n",
    "    \"\"\"\n",
    "    한 문장에 있는 단어의 길이를 계산\n",
    "    parameter tokens: 단어 리스트\n",
    "    return: tokens에 있는 단어의 평균 길이\n",
    "    \"\"\"\n",
    "    word_lengths = [len(word) for word in tokens]\n",
    "    return sum(word_lengths)/len(word_lengths)\n",
    "\n",
    "\n",
    "def compute_total_average_word_length(sentence_list):\n",
    "    \"\"\"\n",
    "    여러 문장에 대한 단어의 평균 길이 계산\n",
    "    param sentence_list: 단어의 리스트로 구성된 문장 리스트\n",
    "    return: sentence_list에 있는 문장의 단어의 평균 길이\n",
    "    \"\"\"\n",
    "    lengths = [compute_average_word_length(tokens) for tokens in sentence_list]\n",
    "    return sum(lengths)/len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9928800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_unique_words_fraction(sentence_list):\n",
    "    \"\"\"\n",
    "    고유한 단어의 비율을 계산\n",
    "    param sentence_list: 단어의 리스트로 구성된 문장 리스트\n",
    "    return: 고유한 단어의 비율\n",
    "    \"\"\"\n",
    "    all_words = [word for word_list in sentence_list for word in word_list]\n",
    "    unique_words = set(all_words)\n",
    "    return len(unique_words)/len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6878f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_usage(tokens, word_list):\n",
    "    \"\"\"\n",
    "    주어진 단어 리스트의 등장 횟수\n",
    "    param tokens: 문장의 단어 리스트\n",
    "    param word_list: 탐색하려는 단어의 리스트\n",
    "    return: 주어진 단어 리스트의 등장 횟수\n",
    "    \"\"\"\n",
    "    return len([word for word in tokens if word.lower() in word_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9bee3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_syllabels(word):\n",
    "    \"\"\"\n",
    "    단어에 있는 음절의 개수를 셈\n",
    "    param word: 단어\n",
    "    return 단어에 있는 음절의 수\n",
    "    \"\"\"\n",
    "    dic = pyphen.Pyphen(lang=\"en_US\")\n",
    "    hyphenated = dic.inserted(word)\n",
    "    return len(hyphenated.split(\"-\"))\n",
    "\n",
    "\n",
    "def count_sentene_syllabels(tokens):\n",
    "    \"\"\"\n",
    "    문장에 있는 음절의 개수를 셈\n",
    "    param tokens: 단어와 구둣점의 리스트\n",
    "    return: 문장에 있는 음절의 수\n",
    "    \"\"\"\n",
    "    punctuation = \".,!?/\"\n",
    "    return sum(\n",
    "        [\n",
    "            count_word_syllabels(word)\n",
    "            for word in tokens\n",
    "            if word not in punctation\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def count_total_syllabels(sentence_list):\n",
    "    \"\"\"\n",
    "    문장 리스트에 있는 음절의 개수를 셈\n",
    "    param sentence_list: 단어의 리스트로 구성된 문장 리스트\n",
    "    return: 문장 리스트에 있는 음절의 개수\n",
    "    \"\"\"\n",
    "    return sum(\n",
    "        [\n",
    "            count_sentecne_syllabels(tokens)\n",
    "            for tokens in sentence_list\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def count_words_per_sentence(sentence_tokens):\n",
    "    \"\"\"\n",
    "    문장에 있는 단어의 개수를 셈\n",
    "    param sentence_tokens: 단어와 구둣점의 리스트\n",
    "    return: 문장에 있는 단어의 수\n",
    "    \"\"\"\n",
    "    punctuation = \".,!?/\"\n",
    "    return len([word for word in sentence_tokens if word not in punctuation])\n",
    "\n",
    "\n",
    "def count_total_words(sentence_list):\n",
    "    \"\"\"\n",
    "    총 단어의 개수를 셈\n",
    "    param sentence_list: 단어의 리스트로 구성된 문장 리스트\n",
    "    return:총 단어의 개수\n",
    "    \"\"\"\n",
    "    return sum([count_words_per_sentence(tokens) for tokens in sentence_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f595afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_flesch_reading_ease(total_syllabels, total_words, total_sentences):\n",
    "    \"\"\"\n",
    "    요약 통계로부터 가독성 점수를 계산\n",
    "    return a readibility score: 점수가 낮을수록 더 복잡한 텍스트임\n",
    "    \"\"\"\n",
    "    return (206.85 - 1.015*(total_words/total_sentences) - 84.6*(total_syllabels/total_words))\n",
    "\n",
    "\n",
    "def get_reading_level_from_flesch(flesch_score):\n",
    "    \"\"\"\n",
    "    https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests 에서 가져온 임곗값\n",
    "    :param flesch_score:\n",
    "    :return: 플레시 점수에 대한 가독성 수준\n",
    "    \"\"\"\n",
    "    if flesch_score < 30:\n",
    "        return \"매우 읽기 어려움\"\n",
    "    elif flesch_score < 50:\n",
    "        return \"읽기 어려움\"\n",
    "    elif flesch_score < 60:\n",
    "        return \"약간 읽기 어려움\"\n",
    "    elif flesch_score < 70:\n",
    "        return \"보통\"\n",
    "    elif flesch_score < 80:\n",
    "        return \"약간 읽기 쉬움\"\n",
    "    elif flesch_score < 90:\n",
    "        return \"읽기 쉬움\"\n",
    "    else:\n",
    "        return \"매우 읽기 쉬움\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b64de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suggestions(sentence_list):\n",
    "    told_said_usage = sum(\n",
    "        (count_word_usage(tokens, [\"told\", \"said\"]) for tokens in sentence_list)\n",
    "    )\n",
    "    but_and_usage = sum(\n",
    "        (count_word_usage(tokens, [\"but\", \"and\"]) for tokens in sentence_list)\n",
    "    )\n",
    "    wh_adverbs_usage = sum(\n",
    "        (\n",
    "            count_word_usage(\n",
    "                tokens,\n",
    "                [\n",
    "                    \"when\",\n",
    "                    \"where\",\n",
    "                    \"why\",\n",
    "                    \"whence\",\n",
    "                    \"whereby\",\n",
    "                    \"wherein\",\n",
    "                    \"whereupon\",\n",
    "                ],\n",
    "            )\n",
    "            for tokens in sentence_list\n",
    "        )\n",
    "    )\n",
    "    result_str = \"\"\n",
    "    adverb_usage = \"단어 사용량: %s told/said, %s but/and, %s wh-접속사\" % (told_said_usage, but_and_usage, wh_adverbs_usage,)\n",
    "    result_str += adverb_usage\n",
    "    \n",
    "    average_word_length = compute_total_average_word_length(sentence_list)\n",
    "    unique_words_fraction = compute_total_unique_words_fraction(sentence_list)\n",
    "    \n",
    "    word_stats = \"평균 단어 길이 %.2f, 고유한 단어의 비율 %.2f\" % (average_word_length, unique_words_fraction,)\n",
    "    \n",
    "    result_str += \"<br/>\"\n",
    "    result_str += word_stats\n",
    "    \n",
    "    number_of_syllabels = count_total_syllabels(sentence_list)\n",
    "    number_of_words = count_total_words(sentence_list)\n",
    "    number_of_sentences = len(sentence_list)\n",
    "    \n",
    "    syllabels_counts = \"%d개 음절, %d개 단어, %d개 문장\" % (number_of_syllabels, number_of_words, number_of_sentences,)\n",
    "    \n",
    "    result_str += \"<br/>\"\n",
    "    result_str += syllabels_counts\n",
    "    \n",
    "    flesch_score = compute_flesch_reading_ease(number_of_syllabels, number_of_words, number_of_sentences)\n",
    "    flesch = \"플레시 점수 %.2f: %s\" % (flesch_score, get_reading_level_from_flesch(flesch_score),)\n",
    "    \n",
    "    result_str += \"<br/>\"\n",
    "    result_str += flesch\n",
    "    \n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d68525b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_from_input(txt):\n",
    "    \"\"\"\n",
    "    입력 문자열에 대한 정제, 전처리하고 경험 규칙 기반의 추천을 생성\n",
    "    return: 텍스트 입력에 대한 추천\n",
    "    \"\"\"\n",
    "    processed = clean_input(txt)\n",
    "    tokenized_sentences = preprocess_input(processed)\n",
    "    suggestions = get_suggestions(tokenized_sentences)\n",
    "    return suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cc7532a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] input text\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    input_text = parse_arguments()\n",
    "    print(get_recommendations_from_input(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00fbe3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
